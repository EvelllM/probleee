import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.multiclass import OneVsRestClassifier
from sklearn.decomposition import PCA
from sklearn.preprocessing import label_binarize
from sklearn.metrics import auc
from sklearn.feature_selection import RFE, SelectKBest, f_classif
from sklearn.inspection import permutation_importance
from scipy.stats import randint, uniform
import pickle
import os
import warnings
import time

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
class EnhancedBearingDiagnosisModel:
    def __init__(self, features_path=None):
        """åˆå§‹åŒ–å¢å¼ºè¯Šæ–­æ¨¡å‹"""
        self.features_path = features_path or 'shouDongChuLi\\result\\Final_selected_features_dataset.xlsx'
        self.features_df = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.models = {}
        self.model_scores = {}
        self.best_model = None
        self.selected_features = None

        # åˆ›å»ºç»“æœæ–‡ä»¶å¤¹
        self.results_dir = "Q-2æ”¹è¿›result"
        if not os.path.exists(self.results_dir):
            os.makedirs(self.results_dir)

    def load_features(self):
        """åŠ è½½ç‰¹å¾æ•°æ®"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            file_extension = os.path.splitext(self.features_path)[1].lower()

            if file_extension == '.xlsx':
                # è¯»å–Excelæ–‡ä»¶
                self.features_df = pd.read_excel(self.features_path)
            elif file_extension == '.csv':
                # å°è¯•å¤šç§ç¼–ç è¯»å–CSVæ–‡ä»¶
                encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312']
                for encoding in encodings:
                    try:
                        # æ·»åŠ æ›´å¤šå‚æ•°æ¥å¤„ç†CSVæ ¼å¼é—®é¢˜
                        self.features_df = pd.read_csv(
                            self.features_path,
                            encoding=encoding,
                            sep=',',  # æ˜ç¡®æŒ‡å®šåˆ†éš”ç¬¦
                            quotechar='"',  # æŒ‡å®šå¼•å·å­—ç¬¦
                            skipinitialspace=True,  # è·³è¿‡åˆ†éš”ç¬¦åçš„ç©ºæ ¼
                            engine='c'  # ä½¿ç”¨Cå¼•æ“ï¼Œæ›´å¿«æ›´å‡†ç¡®
                        )
                        print(f"æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç è¯»å–æ–‡ä»¶")
                        # éªŒè¯æ•°æ®æ˜¯å¦æ­£ç¡®è¯»å–ï¼ˆæ£€æŸ¥åˆ—æ•°ï¼‰
                        if len(self.features_df.columns) > 10:  # åº”è¯¥æœ‰å¾ˆå¤šåˆ—
                            break
                        else:
                            print(
                                f"è­¦å‘Š: ä½¿ç”¨ {encoding} ç¼–ç åªè¯»å–åˆ° {len(self.features_df.columns)} åˆ—ï¼Œç»§ç»­å°è¯•å…¶ä»–ç¼–ç ")
                            continue
                    except (UnicodeDecodeError, pd.errors.ParserError) as e:
                        print(f"ä½¿ç”¨ {encoding} ç¼–ç å¤±è´¥: {e}")
                        continue
                else:
                    # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œå°è¯•æœ€åŸºæœ¬çš„è¯»å–æ–¹å¼
                    try:
                        self.features_df = pd.read_csv(
                            self.features_path,
                            encoding='utf-8',
                            sep=',',
                            engine='python',
                            error_bad_lines=False,
                            warn_bad_lines=True
                        )
                        print("ä½¿ç”¨åŸºæœ¬æ–¹å¼æˆåŠŸè¯»å–æ–‡ä»¶")
                    except Exception as e:
                        raise ValueError(f"æ— æ³•ä½¿ç”¨ä»»ä½•æ–¹å¼è¯»å–CSVæ–‡ä»¶: {e}")
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_extension}")

            print(f"æˆåŠŸåŠ è½½ç‰¹å¾æ•°æ®ï¼Œå…± {len(self.features_df)} ä¸ªæ ·æœ¬")
            print(f"ç‰¹å¾æ•°é‡: {len(self.features_df.columns)}")
            if 'label' in self.features_df.columns:
                print(f"æ ‡ç­¾åˆ†å¸ƒ:\n{self.features_df['label'].value_counts()}")
            return True
        except Exception as e:
            print(f"åŠ è½½ç‰¹å¾æ•°æ®å¤±è´¥: {e}")
            return False

    def preprocess_data(self, test_size=0.3):
        """æ•°æ®é¢„å¤„ç†"""
        if self.features_df is None:
            print("è¯·å…ˆåŠ è½½ç‰¹å¾æ•°æ®ï¼")
            return False

        # é€‰æ‹©ç‰¹å¾åˆ—
        exclude_cols = ['label', 'filename', 'rpm', 'sampling_frequency', 'bearing_type', 'signal_length',
                        'sensor_position', 'data_source_path', 'data_source_directory', 'fault_severity',
                        'signal_duration_seconds']
        feature_cols = [col for col in self.features_df.columns if col not in exclude_cols]

        X = self.features_df[feature_cols].copy()
        y = self.features_df['label'].copy()

        # å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
        X = X.fillna(X.mean())
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(X.mean())

        # ç¼–ç æ ‡ç­¾
        y_encoded = self.label_encoder.fit_transform(y)

        # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y_encoded, test_size=test_size, random_state=42, stratify=y_encoded
        )

        # ç‰¹å¾ç¼©æ”¾
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_test_scaled = self.scaler.transform(self.X_test)

        # ä¿å­˜ç‰¹å¾åˆ—åï¼ˆæ•°æ®é›†å·²ç»è¿‡ç‰¹å¾é€‰æ‹©ï¼Œç›´æ¥ä½¿ç”¨æ‰€æœ‰ç‰¹å¾ï¼‰
        self.selected_features = feature_cols

        print(f"\næ•°æ®é¢„å¤„ç†å®Œæˆ:")
        print(f"è®­ç»ƒé›†å¤§å°: {self.X_train_scaled.shape}")
        print(f"æµ‹è¯•é›†å¤§å°: {self.X_test_scaled.shape}")
        print(f"ä½¿ç”¨çš„ç‰¹å¾æ•°: {len(self.selected_features)}")

        return True

    def train_core_models(self):
        """è®­ç»ƒ4ç§æ ¸å¿ƒæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆåŒ…æ‹¬åŸºç¡€éšæœºæ£®æ—ï¼‰"""
        print("\n=== å¼€å§‹è®­ç»ƒæ ¸å¿ƒæ¨¡å‹ ===")
        
        # å®šä¹‰4ç§æ ¸å¿ƒæ¨¡å‹
        models = {
            'Random_Forest': RandomForestClassifier(
                n_estimators=100,
                max_depth=15,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                n_jobs=-1
            ),
            'Gradient_Boosting': GradientBoostingClassifier(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            ),
            'SVM_RBF': SVC(
                C=1.0,
                gamma='scale',
                kernel='rbf',
                probability=True,
                random_state=42
            ),
            'Logistic_Regression': LogisticRegression(
                C=1.0,
                penalty='l2',
                solver='liblinear',
                random_state=42,
                n_jobs=-1,
                max_iter=1000
            )
        }
        
        self.models = {}
        self.model_scores = {}
        
        # è®­ç»ƒæ¯ä¸ªæ¨¡å‹
        for name, model in models.items():
            print(f"\nè®­ç»ƒ {name}...")
            start_time = time.time()
            
            try:
                # è®­ç»ƒæ¨¡å‹
                model.fit(self.X_train_scaled, self.y_train)
                
                # é¢„æµ‹
                y_pred = model.predict(self.X_test_scaled)
                y_pred_proba = model.predict_proba(self.X_test_scaled)
                
                # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
                accuracy = accuracy_score(self.y_test, y_pred)
                f1_macro = f1_score(self.y_test, y_pred, average='macro')
                f1_weighted = f1_score(self.y_test, y_pred, average='weighted')
                precision = precision_score(self.y_test, y_pred, average='macro')
                recall = recall_score(self.y_test, y_pred, average='macro')
                training_time = time.time() - start_time
                
                # ä¿å­˜æ¨¡å‹å’Œç»“æœ
                self.models[name] = model
                self.model_scores[name] = {
                    'accuracy': accuracy,
                    'f1_macro': f1_macro,
                    'f1_weighted': f1_weighted,
                    'precision': precision,
                    'recall': recall,
                    'predictions': y_pred,
                    'probabilities': y_pred_proba,
                    'training_time': training_time
                }
                
                print(f"  âœ“ {name} è®­ç»ƒå®Œæˆ:")
                print(f"    å‡†ç¡®ç‡: {accuracy:.4f}")
                print(f"    F1-macro: {f1_macro:.4f}")
                print(f"    F1-weighted: {f1_weighted:.4f}")
                print(f"    ç²¾ç¡®ç‡: {precision:.4f}")
                print(f"    å¬å›ç‡: {recall:.4f}")
                print(f"    è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")
                
            except Exception as e:
                print(f"  âœ— {name} è®­ç»ƒå¤±è´¥: {str(e)}")
                continue
        
        # ç¡®å®šæœ€ä½³æ¨¡å‹
        if self.model_scores:
            best_model_name = max(self.model_scores.keys(), 
                                key=lambda x: self.model_scores[x]['f1_macro'])
            self.best_model = self.models[best_model_name]
            
            print(f"\nğŸ† åŸºç¡€è®­ç»ƒæœ€ä½³æ¨¡å‹: {best_model_name}")
            print(f"F1-macroå¾—åˆ†: {self.model_scores[best_model_name]['f1_macro']:.4f}")
        
        return True

    def optimize_random_forest_with_pso(self, n_particles=20, n_iterations=25):
        """ä½¿ç”¨PSOä¼˜åŒ–éšæœºæ£®æ—è¶…å‚æ•°"""
        print("\n=== å¼€å§‹PSOè¶…å‚æ•°ä¼˜åŒ– ===")
        
        # å®šä¹‰æœç´¢ç©ºé—´
        search_space = {
            "n_estimators": (50, 500),
            "max_depth": (5, 30),
            "min_samples_split": (2, 20),
            "min_samples_leaf": (1, 10)
        }
        
        def decode_particle(vec):
            """å°†ç²’å­å‘é‡è§£ç ä¸ºè¶…å‚æ•°"""
            params = {
                "n_estimators": int(np.clip(vec[0], *search_space["n_estimators"])),
                "max_depth": int(np.clip(vec[1], *search_space["max_depth"])),
                "min_samples_split": int(np.clip(vec[2], *search_space["min_samples_split"])),
                "min_samples_leaf": int(np.clip(vec[3], *search_space["min_samples_leaf"])),
                "random_state": 42,
                "n_jobs": -1
            }
            # ç¡®ä¿å‚æ•°åˆç†æ€§
            params["min_samples_split"] = max(params["min_samples_split"], 
                                            params["min_samples_leaf"] + 1)
            return params
        
        def evaluate_particle(vec):
            """è¯„ä¼°ç²’å­æ€§èƒ½"""
            try:
                params = decode_particle(vec)
                model = RandomForestClassifier(**params)
                
                # ä½¿ç”¨äº¤å‰éªŒè¯è¯„ä¼°
                cv_scores = cross_val_score(model, self.X_train_scaled, self.y_train, 
                                          cv=3, scoring='f1_macro', n_jobs=-1)
                return np.mean(cv_scores)
            except:
                return 0.0
        
        # PSOå‚æ•°
        n_dim = 4
        w = 0.72  # æƒ¯æ€§æƒé‡
        c1 = 1.49  # ä¸ªä½“å­¦ä¹ å› å­
        c2 = 1.49  # ç¾¤ä½“å­¦ä¹ å› å­
        
        # åˆå§‹åŒ–ç²’å­ç¾¤
        lows = np.array([search_space["n_estimators"][0], search_space["max_depth"][0],
                        search_space["min_samples_split"][0], search_space["min_samples_leaf"][0]])
        highs = np.array([search_space["n_estimators"][1], search_space["max_depth"][1],
                         search_space["min_samples_split"][1], search_space["min_samples_leaf"][1]])
        
        positions = np.random.uniform(lows, highs, size=(n_particles, n_dim))
        velocities = np.random.uniform(-np.abs(highs-lows), np.abs(highs-lows), 
                                     size=(n_particles, n_dim)) * 0.1
        
        # è¯„ä¼°åˆå§‹ç²’å­
        pbest_pos = positions.copy()
        pbest_val = np.array([evaluate_particle(p) for p in positions])
        
        gbest_idx = np.argmax(pbest_val)
        gbest_pos = pbest_pos[gbest_idx].copy()
        gbest_val = pbest_val[gbest_idx]
        
        print(f"PSOåˆå§‹æœ€ä¼˜F1-macro: {gbest_val:.4f}")
        
        # PSOè¿­ä»£
        for iteration in range(n_iterations):
            # æ›´æ–°é€Ÿåº¦å’Œä½ç½®
            r1 = np.random.random((n_particles, n_dim))
            r2 = np.random.random((n_particles, n_dim))
            
            velocities = (w * velocities + 
                         c1 * r1 * (pbest_pos - positions) + 
                         c2 * r2 * (gbest_pos - positions))
            
            positions = positions + velocities
            positions = np.clip(positions, lows, highs)
            
            # è¯„ä¼°æ–°ä½ç½®
            vals = np.array([evaluate_particle(p) for p in positions])
            
            # æ›´æ–°ä¸ªä½“æœ€ä¼˜
            improved = vals > pbest_val
            pbest_pos[improved] = positions[improved]
            pbest_val[improved] = vals[improved]
            
            # æ›´æ–°å…¨å±€æœ€ä¼˜
            if pbest_val.max() > gbest_val:
                gbest_idx = np.argmax(pbest_val)
                gbest_pos = pbest_pos[gbest_idx].copy()
                gbest_val = pbest_val[gbest_idx]
            
            if (iteration + 1) % 5 == 0:
                print(f"PSOè¿­ä»£ {iteration + 1}/{n_iterations}, å½“å‰æœ€ä¼˜F1-macro: {gbest_val:.4f}")
        
        # ä½¿ç”¨æœ€ä¼˜å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹
        best_params = decode_particle(gbest_pos)
        print(f"\nPSOä¼˜åŒ–å®Œæˆï¼Œæœ€ä¼˜å‚æ•°: {best_params}")
        
        pso_model = RandomForestClassifier(**best_params)
        pso_model.fit(self.X_train_scaled, self.y_train)
        
        # è¯„ä¼°PSOä¼˜åŒ–æ¨¡å‹
        y_pred = pso_model.predict(self.X_test_scaled)
        y_pred_proba = pso_model.predict_proba(self.X_test_scaled)
        
        accuracy = accuracy_score(self.y_test, y_pred)
        f1_macro = f1_score(self.y_test, y_pred, average='macro')
        f1_weighted = f1_score(self.y_test, y_pred, average='weighted')
        
        # ä¿å­˜PSOä¼˜åŒ–æ¨¡å‹
        self.models['RF_PSO_Optimized'] = pso_model
        self.model_scores['RF_PSO_Optimized'] = {
            'accuracy': accuracy,
            'f1_macro': f1_macro,
            'f1_weighted': f1_weighted,
            'predictions': y_pred,
            'probabilities': y_pred_proba,
            'best_params': best_params
        }
        
        print(f"PSOä¼˜åŒ–æ¨¡å‹æ€§èƒ½:")
        print(f"  å‡†ç¡®ç‡: {accuracy:.4f}")
        print(f"  F1-macro: {f1_macro:.4f}")
        print(f"  F1-weighted: {f1_weighted:.4f}")
        
        # æ›´æ–°æœ€ä½³æ¨¡å‹
        if f1_macro > max([score['f1_macro'] for score in self.model_scores.values() 
                          if 'f1_macro' in score]):
            self.best_model = pso_model
            print("PSOä¼˜åŒ–æ¨¡å‹æˆä¸ºæ–°çš„æœ€ä½³æ¨¡å‹ï¼")
        
        return True

    # def feature_selection_analysis(self, n_features=30):
    #     """ç‰¹å¾é€‰æ‹©åˆ†æ"""
    #     print(f"\n=== ç‰¹å¾é€‰æ‹©åˆ†æï¼ˆé€‰æ‹©å‰{n_features}ä¸ªç‰¹å¾ï¼‰===")
        
    #     # ä½¿ç”¨RFEè¿›è¡Œç‰¹å¾é€‰æ‹©
    #     rf_selector = RandomForestClassifier(n_estimators=100, random_state=42)
    #     rfe = RFE(estimator=rf_selector, n_features_to_select=n_features, step=1)
    #     rfe.fit(self.X_train_scaled, self.y_train)
        
    #     # è·å–é€‰æ‹©çš„ç‰¹å¾
    #     selected_features_mask = rfe.support_
    #     selected_feature_names = [self.selected_features[i] for i in range(len(selected_features_mask)) 
    #                             if selected_features_mask[i]]
        
    #     print(f"RFEé€‰æ‹©çš„å‰{n_features}ä¸ªç‰¹å¾:")
    #     for i, feature in enumerate(selected_feature_names, 1):
    #         print(f"  {i:2d}. {feature}")
        
    #     # ä½¿ç”¨é€‰æ‹©çš„ç‰¹å¾è®­ç»ƒæ¨¡å‹
    #     X_train_selected = self.X_train_scaled[:, selected_features_mask]
    #     X_test_selected = self.X_test_scaled[:, selected_features_mask]
        
    #     rf_selected = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
    #     rf_selected.fit(X_train_selected, self.y_train)
        
    #     y_pred_selected = rf_selected.predict(X_test_selected)
        
    #     accuracy_selected = accuracy_score(self.y_test, y_pred_selected)
    #     f1_macro_selected = f1_score(self.y_test, y_pred_selected, average='macro')
        
    #     print(f"\nç‰¹å¾é€‰æ‹©åæ¨¡å‹æ€§èƒ½:")
    #     print(f"  ä½¿ç”¨ç‰¹å¾æ•°: {n_features}")
    #     print(f"  å‡†ç¡®ç‡: {accuracy_selected:.4f}")
    #     print(f"  F1-macro: {f1_macro_selected:.4f}")
        
    #     # ä¿å­˜ç‰¹å¾é€‰æ‹©æ¨¡å‹
    #     self.models['RF_Feature_Selected'] = rf_selected
    #     self.model_scores['RF_Feature_Selected'] = {
    #         'accuracy': accuracy_selected,
    #         'f1_macro': f1_macro_selected,
    #         'predictions': y_pred_selected,
    #         'selected_features': selected_feature_names,
    #         'feature_mask': selected_features_mask
    #     }
        
    #     return selected_feature_names

    def plot_model_comparison(self):
        """ç»˜åˆ¶æ¨¡å‹æ¯”è¾ƒå›¾"""
        print("\n=== ç”Ÿæˆæ¨¡å‹æ¯”è¾ƒå¯è§†åŒ– ===")
        
        # å‡†å¤‡æ•°æ®
        model_names = list(self.model_scores.keys())
        accuracies = [self.model_scores[name]['accuracy'] for name in model_names]
        f1_macros = [self.model_scores[name]['f1_macro'] for name in model_names]
        
        # åˆ›å»ºæ¯”è¾ƒå›¾
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # å‡†ç¡®ç‡æ¯”è¾ƒ
        bars1 = ax1.bar(model_names, accuracies, color='skyblue', alpha=0.7)
        ax1.set_title('æ¨¡å‹å‡†ç¡®ç‡æ¯”è¾ƒ', fontsize=14, fontweight='bold')
        ax1.set_ylabel('å‡†ç¡®ç‡', fontsize=12)
        ax1.set_ylim(0, 1)
        ax1.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, acc in zip(bars1, accuracies):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # F1-macroæ¯”è¾ƒ
        bars2 = ax2.bar(model_names, f1_macros, color='lightcoral', alpha=0.7)
        ax2.set_title('æ¨¡å‹F1-Macroå¾—åˆ†æ¯”è¾ƒ', fontsize=14, fontweight='bold')
        ax2.set_ylabel('F1-Macroå¾—åˆ†', fontsize=12)
        ax2.set_ylim(0, 1)
        ax2.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, f1 in zip(bars2, f1_macros):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{f1:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # æ—‹è½¬xè½´æ ‡ç­¾
        for ax in [ax1, ax2]:
            ax.tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/model_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()

    def plot_confusion_matrices(self):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        print("\n=== ç”Ÿæˆæ··æ·†çŸ©é˜µ ===")
        
        n_models = len(self.models)
        fig, axes = plt.subplots(2, (n_models + 1) // 2, figsize=(15, 10))
        if n_models == 1:
            axes = [axes]
        axes = axes.flatten()
        
        class_names = self.label_encoder.classes_
        
        for idx, (model_name, model) in enumerate(self.models.items()):
            y_pred = self.model_scores[model_name]['predictions']
            cm = confusion_matrix(self.y_test, y_pred)
            
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                       xticklabels=class_names, yticklabels=class_names,
                       ax=axes[idx])
            axes[idx].set_title(f'{model_name} æ··æ·†çŸ©é˜µ')
            axes[idx].set_xlabel('é¢„æµ‹æ ‡ç­¾')
            axes[idx].set_ylabel('çœŸå®æ ‡ç­¾')
        
        # éšè—å¤šä½™çš„å­å›¾
        for idx in range(n_models, len(axes)):
            axes[idx].set_visible(False)
        
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/confusion_matrices.png', dpi=300, bbox_inches='tight')
        plt.show()

    def plot_roc_curves(self):
        """ç»˜åˆ¶ROCæ›²çº¿"""
        print("\n=== ç”ŸæˆROCæ›²çº¿ ===")
        
        class_names = self.label_encoder.classes_
        n_classes = len(class_names)
        
        # äºŒå€¼åŒ–æ ‡ç­¾
        y_test_bin = label_binarize(self.y_test, classes=range(n_classes))
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.flatten()
        
        colors = ['blue', 'red', 'green', 'orange', 'purple']
        
        for class_idx in range(min(n_classes, 4)):  # æœ€å¤šæ˜¾ç¤º4ä¸ªç±»åˆ«
            ax = axes[class_idx]
            
            for model_idx, (model_name, model) in enumerate(self.models.items()):
                if 'probabilities' in self.model_scores[model_name]:
                    y_proba = self.model_scores[model_name]['probabilities']
                    
                    if class_idx < y_proba.shape[1]:
                        fpr, tpr, _ = roc_curve(y_test_bin[:, class_idx], y_proba[:, class_idx])
                        roc_auc = auc(fpr, tpr)
                        
                        ax.plot(fpr, tpr, color=colors[model_idx % len(colors)],
                               label=f'{model_name} (AUC = {roc_auc:.3f})', linewidth=2)
            
            ax.plot([0, 1], [0, 1], 'k--', alpha=0.5)
            ax.set_xlabel('å‡é˜³æ€§ç‡ (FPR)')
            ax.set_ylabel('çœŸé˜³æ€§ç‡ (TPR)')
            ax.set_title(f'ROCæ›²çº¿ - {class_names[class_idx]}')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/roc_curves.png', dpi=300, bbox_inches='tight')
        plt.show()

    def plot_feature_importance(self):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§"""
        print("\n=== ç”Ÿæˆç‰¹å¾é‡è¦æ€§åˆ†æ ===")
        
        if self.best_model is None:
            print("è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼")
            return
        
        # è·å–ç‰¹å¾é‡è¦æ€§
        if hasattr(self.best_model, 'feature_importances_'):
            importances = self.best_model.feature_importances_
            feature_names = self.selected_features
            
            # æ’åº
            indices = np.argsort(importances)[::-1]
            
            # é€‰æ‹©å‰20ä¸ªæœ€é‡è¦çš„ç‰¹å¾
            top_n = min(20, len(importances))
            top_indices = indices[:top_n]
            top_importances = importances[top_indices]
            top_features = [feature_names[i] for i in top_indices]
            
            # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§
            plt.figure(figsize=(12, 8))
            bars = plt.barh(range(top_n), top_importances[::-1], color='lightgreen', alpha=0.7)
            plt.yticks(range(top_n), [top_features[i] for i in range(top_n-1, -1, -1)])
            plt.xlabel('ç‰¹å¾é‡è¦æ€§')
            plt.title('éšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆå‰20ä¸ªç‰¹å¾ï¼‰', fontsize=14, fontweight='bold')
            plt.grid(True, alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, bar in enumerate(bars):
                plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2,
                        f'{top_importances[top_n-1-i]:.3f}', 
                        va='center', ha='left', fontsize=9)
            
            plt.tight_layout()
            plt.savefig(f'{self.results_dir}/feature_importance_analysis.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            # ä¿å­˜ç‰¹å¾é‡è¦æ€§åˆ°CSV
            importance_df = pd.DataFrame({
                'feature': top_features,
                'importance': top_importances
            })
            importance_df.to_csv(f'{self.results_dir}/feature_importance.csv', index=False)
            print(f"ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜åˆ° {self.results_dir}/feature_importance.csv")

    def generate_classification_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š"""
        print("\n=== ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š ===")
        
        class_names = self.label_encoder.classes_
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹ç”ŸæˆæŠ¥å‘Š
        all_reports = {}
        
        for model_name in self.models.keys():
            y_pred = self.model_scores[model_name]['predictions']
            
            # ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
            report = classification_report(self.y_test, y_pred, 
                                         target_names=class_names, 
                                         output_dict=True)
            all_reports[model_name] = report
            
            print(f"\n{model_name} åˆ†ç±»æŠ¥å‘Š:")
            print(classification_report(self.y_test, y_pred, target_names=class_names))
        
        # ä¿å­˜æŠ¥å‘Šåˆ°CSV
        report_data = []
        for model_name, report in all_reports.items():
            for class_name in class_names:
                if class_name in report:
                    report_data.append({
                        'model': model_name,
                        'class': class_name,
                        'precision': report[class_name]['precision'],
                        'recall': report[class_name]['recall'],
                        'f1-score': report[class_name]['f1-score'],
                        'support': report[class_name]['support']
                    })
            
            # æ·»åŠ æ€»ä½“æŒ‡æ ‡
            report_data.append({
                'model': model_name,
                'class': 'macro avg',
                'precision': report['macro avg']['precision'],
                'recall': report['macro avg']['recall'],
                'f1-score': report['macro avg']['f1-score'],
                'support': report['macro avg']['support']
            })
        
        report_df = pd.DataFrame(report_data)
        report_df.to_csv(f'{self.results_dir}/classification_report.csv', index=False)
        print(f"åˆ†ç±»æŠ¥å‘Šå·²ä¿å­˜åˆ° {self.results_dir}/classification_report.csv")

    def save_best_model(self):
        """ä¿å­˜æœ€ä½³æ¨¡å‹"""
        if self.best_model is not None:
            model_path = f'{self.results_dir}/best_bearing_model.pkl'
            
            # ä¿å­˜æ¨¡å‹å’Œç›¸å…³ä¿¡æ¯
            model_info = {
                'model': self.best_model,
                'scaler': self.scaler,
                'label_encoder': self.label_encoder,
                'selected_features': self.selected_features,
                'model_scores': self.model_scores
            }
            
            with open(model_path, 'wb') as f:
                pickle.dump(model_info, f)
            
            print(f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ° {model_path}")
        else:
            print("æ²¡æœ‰å¯ä¿å­˜çš„æ¨¡å‹ï¼")

    def _print_final_summary(self):
        """æ‰“å°æœ€ç»ˆç»“æœæ€»ç»“"""
        print("\nğŸ“Š æœ€ç»ˆè¯Šæ–­ç»“æœæ€»ç»“:")
        print("-" * 50)
        
        if not self.model_scores:
            print("âŒ æ²¡æœ‰æ¨¡å‹è¯„ä¼°ç»“æœå¯æ˜¾ç¤º")
            return
        
        # æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½
        print(f"ğŸ“ˆ å…±è®­ç»ƒäº† {len(self.model_scores)} ä¸ªæ¨¡å‹:")
        
        # æŒ‰F1-macroåˆ†æ•°æ’åº
        sorted_models = sorted(self.model_scores.items(), 
                             key=lambda x: x[1]['f1_macro'], 
                             reverse=True)
        
        for i, (model_name, scores) in enumerate(sorted_models, 1):
            print(f"  {i}. {model_name}:")
            print(f"     å‡†ç¡®ç‡: {scores['accuracy']:.4f}")
            print(f"     F1-macro: {scores['f1_macro']:.4f}")
            print(f"     ç²¾ç¡®ç‡: {scores['precision']:.4f}")
            print(f"     å¬å›ç‡: {scores['recall']:.4f}")
            if i == 1:
                print("     ğŸ† æœ€ä½³æ¨¡å‹")
            print()
        
        # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹ä¿¡æ¯
        if hasattr(self, 'best_model') and self.best_model is not None:
            best_model_name = max(self.model_scores.items(), 
                                key=lambda x: x[1]['f1_macro'])[0]
            print(f"ğŸ¯ æœ€ä½³æ¨¡å‹: {best_model_name}")
            print(f"ğŸ¯ æœ€ä½³F1-macroå¾—åˆ†: {max(score['f1_macro'] for score in self.model_scores.values()):.4f}")
        
        # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
        if hasattr(self, 'X_train') and hasattr(self, 'X_test'):
            print(f"\nğŸ“‹ æ•°æ®é›†ä¿¡æ¯:")
            print(f"   è®­ç»ƒé›†æ ·æœ¬æ•°: {len(self.X_train)}")
            print(f"   æµ‹è¯•é›†æ ·æœ¬æ•°: {len(self.X_test)}")
            print(f"   ç‰¹å¾æ•°é‡: {self.X_train.shape[1] if hasattr(self.X_train, 'shape') else 'N/A'}")
        
        # æ˜¾ç¤ºæ•…éšœç±»åˆ«ä¿¡æ¯
        if hasattr(self, 'label_encoder') and self.label_encoder is not None:
            print(f"   æ•…éšœç±»åˆ«æ•°: {len(self.label_encoder.classes_)}")
            print(f"   æ•…éšœç±»åˆ«: {', '.join(self.label_encoder.classes_)}")

    def optimize_selected_models(self):
        """å¯¹å€¼å¾—æ¢ç´¢çš„æ¨¡å‹è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–ï¼ˆéšæœºæ£®æ—å’Œæ¢¯åº¦æå‡ï¼‰"""
        print("\n=== å¼€å§‹å¯¹é€‰å®šæ¨¡å‹è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ– ===")
        
        # åªå¯¹å€¼å¾—æ¢ç´¢çš„æ¨¡å‹è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–
        models_to_optimize = ['Random_Forest', 'Gradient_Boosting']
        
        # å®šä¹‰è¶…å‚æ•°æœç´¢ç©ºé—´ï¼ˆè¿ç»­åŒºé—´èŒƒå›´ï¼‰
        param_distributions = {
            'Random_Forest': {
                'n_estimators': randint(50, 300),           # 100-300ä¹‹é—´çš„æ•´æ•°
                'max_depth': randint(5, 30),                # 10-30ä¹‹é—´çš„æ•´æ•°
                'min_samples_split': randint(2, 20),         # 2-10ä¹‹é—´çš„æ•´æ•°
                'min_samples_leaf': randint(1, 10),           # 1-5ä¹‹é—´çš„æ•´æ•°
                'max_features': uniform(0.5, 0.5)           # 0.5-1.0ä¹‹é—´çš„è¿ç»­å€¼
            },
            'Gradient_Boosting': {
                'n_estimators': randint(100, 300),           # 100-300ä¹‹é—´çš„æ•´æ•°ï¼Œå¢åŠ ä¸Šé™
                'learning_rate': uniform(0.01, 0.25),       # 0.01-0.25ä¹‹é—´çš„è¿ç»­å€¼ï¼Œæ‰©å±•èŒƒå›´
                'max_depth': randint(3, 8),                  # 3-8ä¹‹é—´çš„æ•´æ•°ï¼Œä¿®æ­£ä¸ºåˆç†èŒƒå›´
                'subsample': uniform(0.7, 0.3),             # 0.7-1.0ä¹‹é—´çš„è¿ç»­å€¼ï¼Œæ‰©å±•ä¸‹é™
                'min_samples_split': randint(2, 15),         # 2-15ä¹‹é—´çš„æ•´æ•°ï¼Œé€‚åº¦æ‰©å±•
                'min_samples_leaf': randint(1, 8)            # 1-8ä¹‹é—´çš„æ•´æ•°ï¼Œé€‚åº¦æ‰©å±• 
            }
        }
        
        # å®šä¹‰åŸºç¡€æ¨¡å‹
        base_models = {
            'Random_Forest': RandomForestClassifier(random_state=42, n_jobs=-1),
            'Gradient_Boosting': GradientBoostingClassifier(random_state=42)
        }
        
        optimized_models = {}
        
        print(f"å°†å¯¹ä»¥ä¸‹æ¨¡å‹è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–: {', '.join(models_to_optimize)}")
        print("å…¶ä»–æ¨¡å‹ï¼ˆSVM_RBF, Logistic_Regressionï¼‰ä¿æŒåŸºç¡€é…ç½®")
        
        # å¯¹é€‰å®šçš„æ¨¡å‹è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–
        for model_name in models_to_optimize:
            if model_name in self.models:
                print(f"\nğŸ”§ ä¼˜åŒ– {model_name}...")
                start_time = time.time()
                
                try:
                    # åˆ›å»ºRandomizedSearchCVè¿›è¡ŒåŒºé—´æœç´¢
                    random_search = RandomizedSearchCV(
                        estimator=base_models[model_name],
                        param_distributions=param_distributions[model_name],
                        n_iter=50,  # éšæœºæœç´¢50æ¬¡
                        cv=3,
                        scoring='f1_macro',
                        n_jobs=-1,
                        verbose=0,
                        random_state=42
                    )
                    
                    # æ‰§è¡Œéšæœºæœç´¢
                    random_search.fit(self.X_train_scaled, self.y_train)
                    
                    # è·å–æœ€ä½³æ¨¡å‹
                    best_model = random_search.best_estimator_
                    
                    # é¢„æµ‹
                    y_pred = best_model.predict(self.X_test_scaled)
                    y_pred_proba = best_model.predict_proba(self.X_test_scaled)
                    
                    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
                    accuracy = accuracy_score(self.y_test, y_pred)
                    f1_macro = f1_score(self.y_test, y_pred, average='macro')
                    f1_weighted = f1_score(self.y_test, y_pred, average='weighted')
                    precision = precision_score(self.y_test, y_pred, average='macro')
                    recall = recall_score(self.y_test, y_pred, average='macro')
                    optimization_time = time.time() - start_time
                    
                    # ä¿å­˜ä¼˜åŒ–åçš„æ¨¡å‹
                    optimized_name = f"{model_name}_Optimized"
                    optimized_models[optimized_name] = best_model
                    self.model_scores[optimized_name] = {
                        'accuracy': accuracy,
                        'f1_macro': f1_macro,
                        'f1_weighted': f1_weighted,
                        'precision': precision,
                        'recall': recall,
                        'predictions': y_pred,
                        'probabilities': y_pred_proba,
                        'best_params': random_search.best_params_,
                        'optimization_time': optimization_time,
                        'cv_score': random_search.best_score_
                    }
                    
                    print(f"  âœ… {model_name} ä¼˜åŒ–å®Œæˆ:")
                    print(f"    æœ€ä½³å‚æ•°: {random_search.best_params_}")
                    print(f"    äº¤å‰éªŒè¯å¾—åˆ†: {random_search.best_score_:.4f}")
                    print(f"    æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}")
                    print(f"    æµ‹è¯•é›†F1-macro: {f1_macro:.4f}")
                    print(f"    ä¼˜åŒ–æ—¶é—´: {optimization_time:.2f}ç§’")
                    
                    # æ¯”è¾ƒä¼˜åŒ–å‰åçš„æ€§èƒ½
                    original_f1 = self.model_scores[model_name]['f1_macro']
                    improvement = f1_macro - original_f1
                    print(f"    æ€§èƒ½æå‡: {improvement:+.4f}")
                    
                except Exception as e:
                    print(f"  âŒ {model_name} ä¼˜åŒ–å¤±è´¥: {str(e)}")
                    continue
            else:
                print(f"âš ï¸ æ¨¡å‹ {model_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¼˜åŒ–")
        
        # æ›´æ–°æ¨¡å‹å­—å…¸
        self.models.update(optimized_models)
        
        # ç¡®å®šæœ€ä½³æ¨¡å‹ï¼ˆåŒ…æ‹¬ä¼˜åŒ–åçš„æ¨¡å‹ï¼‰
        if self.model_scores:
            best_model_name = max(self.model_scores.keys(), 
                                key=lambda x: self.model_scores[x]['f1_macro'])
            self.best_model = self.models[best_model_name]
            
            print(f"\nğŸ† è¶…å‚æ•°ä¼˜åŒ–åçš„æœ€ä½³æ¨¡å‹: {best_model_name}")
            print(f"F1-macroå¾—åˆ†: {self.model_scores[best_model_name]['f1_macro']:.4f}")
            
            if 'best_params' in self.model_scores[best_model_name]:
                print(f"æœ€ä½³å‚æ•°: {self.model_scores[best_model_name]['best_params']}")
        
        print(f"\nğŸ“Š å½“å‰å…±æœ‰ {len(self.models)} ä¸ªæ¨¡å‹:")
        for name in self.models.keys():
            f1_macro_score = self.model_scores[name]['f1_macro']
            print(f"  - {name}: F1-macro = {f1_macro_score:.4f}")
        
        return True

    def run_complete_diagnosis(self):
        """è¿è¡Œå®Œæ•´çš„è¯Šæ–­æµç¨‹"""
        print("ğŸš€ å¼€å§‹è½´æ‰¿æ•…éšœæ™ºèƒ½è¯Šæ–­åˆ†æ...")
        
        # 1. åŠ è½½æ•°æ®
        print("\n" + "="*50)
        print("ç¬¬1æ­¥: åŠ è½½ç‰¹å¾æ•°æ®")
        if not self.load_features():
            return False
        
        # 2. æ•°æ®é¢„å¤„ç†
        print("\n" + "="*50)
        print("ç¬¬2æ­¥: æ•°æ®é¢„å¤„ç†")
        if not self.preprocess_data():
            return False
        
        # 3. è®­ç»ƒæ ¸å¿ƒæ¨¡å‹
        print("\n" + "="*50)
        print("ç¬¬3æ­¥: è®­ç»ƒæ ¸å¿ƒæ¨¡å‹")
        self.train_core_models()
        
        # 4. å¯¹é€‰å®šæ¨¡å‹è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–
        print("\n" + "="*50)
        print("ç¬¬4æ­¥: è¶…å‚æ•°ä¼˜åŒ–")
        self.optimize_selected_models()
        
        # 5. ç”Ÿæˆå¯è§†åŒ–ç»“æœ
        print("\n" + "="*50)
        print("ç¬¬5æ­¥: ç”Ÿæˆå¯è§†åŒ–ç»“æœ")
        self.plot_model_comparison()
        self.plot_confusion_matrices()
        self.plot_roc_curves()
        self.plot_feature_importance()
        
        # 6. ç”ŸæˆæŠ¥å‘Š
        print("\n" + "="*50)
        print("ç¬¬6æ­¥: ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š")
        self.generate_classification_report()
        
        # 7. ä¿å­˜æœ€ä½³æ¨¡å‹
        print("\n" + "="*50)
        print("ç¬¬7æ­¥: ä¿å­˜æœ€ä½³æ¨¡å‹")
        self.save_best_model()
        
        # 8. æ˜¾ç¤ºæœ€ç»ˆç»“æœæ€»ç»“
        print("\n" + "="*50)
        print("ç¬¬8æ­¥: æœ€ç»ˆç»“æœæ€»ç»“")
        self._print_final_summary()
        
        print("\nğŸ‰ è½´æ‰¿æ•…éšœæ™ºèƒ½è¯Šæ–­åˆ†æå®Œæˆï¼")
        return True


def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºè¯Šæ–­æ¨¡å‹
    model = EnhancedBearingDiagnosisModel()
    
    # è¿è¡Œå®Œæ•´è¯Šæ–­æµç¨‹
    success = model.run_complete_diagnosis()
    
    if success:
        print("\n=== è¯Šæ–­ç»“æœæ‘˜è¦ ===")
        print(f"è®­ç»ƒçš„æ¨¡å‹æ•°é‡: {len(model.models)}")
        print(f"æœ€ä½³æ¨¡å‹æ€§èƒ½:")
        
        best_scores = max(model.model_scores.values(), key=lambda x: x['f1_macro'])
        print(f"  å‡†ç¡®ç‡: {best_scores['accuracy']:.4f}")
        print(f"  F1-macro: {best_scores['f1_macro']:.4f}")
        print(f"  F1-weighted: {best_scores['f1_weighted']:.4f}")
        
        print(f"\næ‰€æœ‰ç»“æœæ–‡ä»¶å·²ä¿å­˜åˆ°: {model.results_dir}")
    else:
        print("è¯Šæ–­æµç¨‹æ‰§è¡Œå¤±è´¥ï¼")


if __name__ == "__main__":
    main()