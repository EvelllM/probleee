import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import os
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
import warnings
from datetime import datetime

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

class TargetDomainPredictor:
    def __init__(self, model_path, target_data_path):
        """
        åˆå§‹åŒ–ç›®æ ‡åŸŸé¢„æµ‹å™¨
        
        Args:
            model_path: è®­ç»ƒå¥½çš„æ¨¡åž‹æ–‡ä»¶è·¯å¾„
            target_data_path: ç›®æ ‡åŸŸæ ‡å‡†åŒ–æ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.model_path = model_path
        self.target_data_path = target_data_path
        self.model = None
        self.target_data = None
        self.sample_ids = None
        self.predictions = None
        self.prediction_probabilities = None
        self.label_encoder = None
        
        # åˆ›å»ºç»“æžœä¿å­˜ç›®å½•
        self.results_dir = "Q3è¿ç§»å­¦ä¹ é¢„æµ‹ç»“æžœ-2"
        if not os.path.exists(self.results_dir):
            os.makedirs(self.results_dir)
    
    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡åž‹"""
        try:
            print("æ­£åœ¨åŠ è½½è®­ç»ƒå¥½çš„æ¨¡åž‹...")
            with open(self.model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            # æ£€æŸ¥æ¨¡åž‹æ•°æ®ç»“æž„
            if isinstance(model_data, dict):
                self.model = model_data.get('model')
                self.label_encoder = model_data.get('label_encoder')
                print(f"æˆåŠŸåŠ è½½æ¨¡åž‹: {type(self.model).__name__}")
                
                # å¦‚æžœæœ‰æ ‡ç­¾ç¼–ç å™¨ï¼Œæ‰“å°ç±»åˆ«ä¿¡æ¯
                if self.label_encoder:
                    print(f"æ¨¡åž‹ç±»åˆ«: {self.label_encoder.classes_}")
                else:
                    # åˆ›å»ºé»˜è®¤çš„æ ‡ç­¾ç¼–ç å™¨ï¼ˆåŸºäºŽæºåŸŸæ•°æ®çš„å¸¸è§ç±»åˆ«ï¼‰
                    self.label_encoder = LabelEncoder()
                    # å‡è®¾çš„è½´æ‰¿æ•…éšœç±»åˆ«
                    default_classes = ['Normal', 'Inner_Race', 'Outer_Race', 'Ball', 'Cage']
                    self.label_encoder.fit(default_classes)
                    print(f"ä½¿ç”¨é»˜è®¤ç±»åˆ«: {default_classes}")
            else:
                # å¦‚æžœç›´æŽ¥æ˜¯æ¨¡åž‹å¯¹è±¡
                self.model = model_data
                print(f"æˆåŠŸåŠ è½½æ¨¡åž‹: {type(self.model).__name__}")
                
                # åˆ›å»ºé»˜è®¤çš„æ ‡ç­¾ç¼–ç å™¨
                self.label_encoder = LabelEncoder()
                default_classes = ['Normal', 'Inner_Race', 'Outer_Race', 'Ball', 'Cage']
                self.label_encoder.fit(default_classes)
                print(f"ä½¿ç”¨é»˜è®¤ç±»åˆ«: {default_classes}")
            
            return True
            
        except Exception as e:
            print(f"åŠ è½½æ¨¡åž‹å¤±è´¥: {e}")
            return False
    
    def load_target_data(self):
        """åŠ è½½ç›®æ ‡åŸŸæ ‡å‡†åŒ–æ•°æ®"""
        try:
            print("æ­£åœ¨åŠ è½½ç›®æ ‡åŸŸæ•°æ®...")
            self.target_data = pd.read_csv(self.target_data_path)
            
            # æå–æ ·æœ¬IDï¼ˆç¬¬ä¸€åˆ—ï¼‰
            if self.target_data.columns[0] == 'Unnamed: 0':
                # å¦‚æžœç¬¬ä¸€åˆ—æ˜¯ç´¢å¼•åˆ—ï¼Œæ ·æœ¬IDåœ¨ç´¢å¼•ä¸­
                self.sample_ids = self.target_data.iloc[:, 0].tolist()
                self.target_data = self.target_data.iloc[:, 1:]
            else:
                # å¦‚æžœç¬¬ä¸€åˆ—å°±æ˜¯æ ·æœ¬ID
                self.sample_ids = self.target_data.iloc[:, 0].tolist()
                self.target_data = self.target_data.iloc[:, 1:]
            
            print(f"æˆåŠŸåŠ è½½ç›®æ ‡åŸŸæ•°æ®: {self.target_data.shape}")
            print(f"æ ·æœ¬ID: {self.sample_ids}")
            print(f"ç‰¹å¾åˆ—: {list(self.target_data.columns)}")
            
            # æ£€æŸ¥æ•°æ®è´¨é‡
            print(f"ç¼ºå¤±å€¼æ•°é‡: {self.target_data.isnull().sum().sum()}")
            print(f"æ— ç©·å€¼æ•°é‡: {np.isinf(self.target_data.values).sum()}")
            
            return True
            
        except Exception as e:
            print(f"åŠ è½½ç›®æ ‡åŸŸæ•°æ®å¤±è´¥: {e}")
            return False
    
    def predict_target_domain(self):
        """å¯¹ç›®æ ‡åŸŸæ•°æ®è¿›è¡Œé¢„æµ‹"""
        try:
            print("\næ­£åœ¨è¿›è¡Œç›®æ ‡åŸŸé¢„æµ‹...")
            
            # ç¡®ä¿æ•°æ®æ˜¯æ•°å€¼åž‹
            X = self.target_data.values.astype(float)
            
            # å¤„ç†å¯èƒ½çš„å¼‚å¸¸å€¼
            X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
            
            # è¿›è¡Œé¢„æµ‹
            self.predictions = self.model.predict(X)
            self.prediction_probabilities = self.model.predict_proba(X)
            
            # è½¬æ¢é¢„æµ‹ç»“æžœä¸ºç±»åˆ«åç§°
            predicted_labels = self.label_encoder.inverse_transform(self.predictions)
            
            print(f"é¢„æµ‹å®Œæˆï¼Œå…±é¢„æµ‹ {len(self.predictions)} ä¸ªæ ·æœ¬")
            
            # ç»Ÿè®¡é¢„æµ‹ç»“æžœ
            unique, counts = np.unique(predicted_labels, return_counts=True)
            print("\né¢„æµ‹ç»“æžœç»Ÿè®¡:")
            for label, count in zip(unique, counts):
                percentage = count / len(predicted_labels) * 100
                print(f"  {label}: {count} ä¸ªæ ·æœ¬ ({percentage:.1f}%)")
            
            return predicted_labels
            
        except Exception as e:
            print(f"é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def analyze_prediction_confidence(self):
        """åˆ†æžé¢„æµ‹ç½®ä¿¡åº¦"""
        if self.prediction_probabilities is None:
            print("æ²¡æœ‰é¢„æµ‹æ¦‚çŽ‡æ•°æ®")
            return None
        
        print("\n=== é¢„æµ‹ç½®ä¿¡åº¦åˆ†æž ===")
        
        # è®¡ç®—æœ€å¤§æ¦‚çŽ‡ï¼ˆç½®ä¿¡åº¦ï¼‰
        max_probabilities = np.max(self.prediction_probabilities, axis=1)
        
        # ç»Ÿè®¡ç½®ä¿¡åº¦åˆ†å¸ƒ
        confidence_stats = {
            'å¹³å‡ç½®ä¿¡åº¦': np.mean(max_probabilities),
            'ç½®ä¿¡åº¦ä¸­ä½æ•°': np.median(max_probabilities),
            'ç½®ä¿¡åº¦æ ‡å‡†å·®': np.std(max_probabilities),
            'æœ€å°ç½®ä¿¡åº¦': np.min(max_probabilities),
            'æœ€å¤§ç½®ä¿¡åº¦': np.max(max_probabilities)
        }
        
        for key, value in confidence_stats.items():
            print(f"{key}: {value:.4f}")
        
        # ç½®ä¿¡åº¦åŒºé—´ç»Ÿè®¡
        confidence_ranges = {
            'é«˜ç½®ä¿¡åº¦ (>0.8)': np.sum(max_probabilities > 0.8),
            'ä¸­ç­‰ç½®ä¿¡åº¦ (0.6-0.8)': np.sum((max_probabilities > 0.6) & (max_probabilities <= 0.8)),
            'ä½Žç½®ä¿¡åº¦ (0.4-0.6)': np.sum((max_probabilities > 0.4) & (max_probabilities <= 0.6)),
            'å¾ˆä½Žç½®ä¿¡åº¦ (<=0.4)': np.sum(max_probabilities <= 0.4)
        }
        
        print("\nç½®ä¿¡åº¦åŒºé—´åˆ†å¸ƒ:")
        total_samples = len(max_probabilities)
        for range_name, count in confidence_ranges.items():
            percentage = count / total_samples * 100
            print(f"  {range_name}: {count} ä¸ªæ ·æœ¬ ({percentage:.1f}%)")
        
        return confidence_stats, confidence_ranges
    
    def create_visualizations(self, predicted_labels):
        """åˆ›å»ºé¢„æµ‹ç»“æžœå¯è§†åŒ–"""
        print("\n=== ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ ===")
        
        # åˆ›å»ºå›¾è¡¨
        fig = plt.figure(figsize=(20, 15))
        
        # 1. é¢„æµ‹ç±»åˆ«åˆ†å¸ƒé¥¼å›¾
        ax1 = plt.subplot(2, 3, 1)
        unique_labels, counts = np.unique(predicted_labels, return_counts=True)
        colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))
        
        wedges, texts, autotexts = ax1.pie(counts, labels=unique_labels, autopct='%1.1f%%', 
                                          colors=colors, startangle=90)
        ax1.set_title('ç›®æ ‡åŸŸé¢„æµ‹ç±»åˆ«åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        
        # 2. é¢„æµ‹ç±»åˆ«åˆ†å¸ƒæŸ±çŠ¶å›¾
        ax2 = plt.subplot(2, 3, 2)
        bars = ax2.bar(unique_labels, counts, color=colors, alpha=0.7)
        ax2.set_title('é¢„æµ‹ç±»åˆ«æ•°é‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax2.set_ylabel('æ ·æœ¬æ•°é‡')
        ax2.tick_params(axis='x', rotation=45)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, count in zip(bars, counts):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                    str(count), ha='center', va='bottom', fontweight='bold')
        
        # 3. ç½®ä¿¡åº¦åˆ†å¸ƒç›´æ–¹å›¾
        ax3 = plt.subplot(2, 3, 3)
        max_probabilities = np.max(self.prediction_probabilities, axis=1)
        ax3.hist(max_probabilities, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        ax3.set_title('é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax3.set_xlabel('ç½®ä¿¡åº¦')
        ax3.set_ylabel('é¢‘æ¬¡')
        ax3.axvline(np.mean(max_probabilities), color='red', linestyle='--', 
                   label=f'å¹³å‡å€¼: {np.mean(max_probabilities):.3f}')
        ax3.legend()
        
        # 4. å„ç±»åˆ«ç½®ä¿¡åº¦ç®±çº¿å›¾
        ax4 = plt.subplot(2, 3, 4)
        confidence_by_class = []
        class_labels = []
        
        for label in unique_labels:
            mask = predicted_labels == label
            class_confidence = max_probabilities[mask]
            confidence_by_class.append(class_confidence)
            class_labels.append(label)
        
        box_plot = ax4.boxplot(confidence_by_class, labels=class_labels, patch_artist=True)
        ax4.set_title('å„ç±»åˆ«é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax4.set_ylabel('ç½®ä¿¡åº¦')
        ax4.tick_params(axis='x', rotation=45)
        
        # ä¸ºç®±çº¿å›¾æ·»åŠ é¢œè‰²
        for patch, color in zip(box_plot['boxes'], colors):
            patch.set_facecolor(color)
            patch.set_alpha(0.7)
        
        # 5. å„æ ·æœ¬é¢„æµ‹ç»“æžœå±•ç¤º
        ax5 = plt.subplot(2, 3, 5)
        
        # ä¸ºæ¯ä¸ªç±»åˆ«åˆ†é…æ•°å€¼
        label_to_num = {label: i for i, label in enumerate(unique_labels)}
        numeric_predictions = [label_to_num[label] for label in predicted_labels]
        
        # ä½¿ç”¨æ ·æœ¬IDä½œä¸ºXè½´æ ‡ç­¾ï¼Œå±•ç¤ºæ¯ä¸ªæ–‡ä»¶çš„é¢„æµ‹ç»“æžœ
        ax5.scatter(range(len(self.sample_ids)), numeric_predictions, c=max_probabilities, 
                   cmap='viridis', alpha=0.7, s=50)
        ax5.set_title('å„æ ·æœ¬é¢„æµ‹ç»“æžœ', fontsize=14, fontweight='bold')
        ax5.set_xlabel('æ ·æœ¬æ–‡ä»¶')
        ax5.set_ylabel('é¢„æµ‹ç±»åˆ«')
        ax5.set_xticks(range(len(self.sample_ids)))
        ax5.set_xticklabels(self.sample_ids, rotation=45)  # æ˜¾ç¤ºA, B, C...P
        ax5.set_yticks(range(len(unique_labels)))
        ax5.set_yticklabels(unique_labels)
        ax5.grid(True, alpha=0.3)
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(ax5.collections[0], ax=ax5)
        cbar.set_label('ç½®ä¿¡åº¦')
        
        # 6. ç½®ä¿¡åº¦åŒºé—´ç»Ÿè®¡
        ax6 = plt.subplot(2, 3, 6)
        confidence_ranges = {
            'é«˜ç½®ä¿¡åº¦\n(>0.8)': np.sum(max_probabilities > 0.8),
            'ä¸­ç­‰ç½®ä¿¡åº¦\n(0.6-0.8)': np.sum((max_probabilities > 0.6) & (max_probabilities <= 0.8)),
            'ä½Žç½®ä¿¡åº¦\n(0.4-0.6)': np.sum((max_probabilities > 0.4) & (max_probabilities <= 0.6)),
            'å¾ˆä½Žç½®ä¿¡åº¦\n(<=0.4)': np.sum(max_probabilities <= 0.4)
        }
        
        range_names = list(confidence_ranges.keys())
        range_counts = list(confidence_ranges.values())
        range_colors = ['green', 'orange', 'yellow', 'red']
        
        bars = ax6.bar(range_names, range_counts, color=range_colors, alpha=0.7)
        ax6.set_title('ç½®ä¿¡åº¦åŒºé—´åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax6.set_ylabel('æ ·æœ¬æ•°é‡')
        
        # æ·»åŠ ç™¾åˆ†æ¯”æ ‡ç­¾
        total_samples = len(max_probabilities)
        for bar, count in zip(bars, range_counts):
            percentage = count / total_samples * 100
            ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                    f'{count}\n({percentage:.1f}%)', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        plt.savefig(f'{self.results_dir}/target_domain_prediction_analysis.png', 
                   dpi=300, bbox_inches='tight')
        plt.show()
        
        return fig
    
    def save_prediction_results(self, predicted_labels):
        """ä¿å­˜é¢„æµ‹ç»“æžœåˆ°æ–‡ä»¶"""
        print("\n=== ä¿å­˜é¢„æµ‹ç»“æžœ ===")
        
        try:
            # åˆ›å»ºç»“æžœDataFrame
            results_df = pd.DataFrame({
                'sample_id': self.sample_ids,
                'predicted_label': predicted_labels,
                'predicted_class_id': self.predictions,
                'confidence': np.max(self.prediction_probabilities, axis=1)
            })
            
            # æ·»åŠ å„ç±»åˆ«çš„æ¦‚çŽ‡
            class_names = self.label_encoder.classes_
            for i, class_name in enumerate(class_names):
                results_df[f'prob_{class_name}'] = self.prediction_probabilities[:, i]
            
            # ä¿å­˜è¯¦ç»†ç»“æžœ
            results_path = f'{self.results_dir}/target_domain_predictions.csv'
            results_df.to_csv(results_path, index=False, encoding='utf-8-sig')
            print(f"è¯¦ç»†é¢„æµ‹ç»“æžœå·²ä¿å­˜åˆ°: {results_path}")
            
            # åˆ›å»ºæ±‡æ€»æŠ¥å‘Š
            report_path = f'{self.results_dir}/prediction_summary_report.txt'
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("ç›®æ ‡åŸŸè¿ç§»å­¦ä¹ é¢„æµ‹ç»“æžœæ±‡æ€»æŠ¥å‘Š\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ¨¡åž‹æ–‡ä»¶: {self.model_path}\n")
                f.write(f"ç›®æ ‡åŸŸæ•°æ®: {self.target_data_path}\n")
                f.write(f"æ€»æ ·æœ¬æ•°: {len(predicted_labels)}\n\n")
                
                f.write("é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ:\n")
                f.write("-" * 30 + "\n")
                unique_labels, counts = np.unique(predicted_labels, return_counts=True)
                for label, count in zip(unique_labels, counts):
                    percentage = count / len(predicted_labels) * 100
                    f.write(f"{label}: {count} ä¸ªæ ·æœ¬ ({percentage:.1f}%)\n")
                
                f.write("\nç½®ä¿¡åº¦ç»Ÿè®¡:\n")
                f.write("-" * 30 + "\n")
                max_probabilities = np.max(self.prediction_probabilities, axis=1)
                f.write(f"å¹³å‡ç½®ä¿¡åº¦: {np.mean(max_probabilities):.4f}\n")
                f.write(f"ç½®ä¿¡åº¦ä¸­ä½æ•°: {np.median(max_probabilities):.4f}\n")
                f.write(f"ç½®ä¿¡åº¦æ ‡å‡†å·®: {np.std(max_probabilities):.4f}\n")
                f.write(f"æœ€å°ç½®ä¿¡åº¦: {np.min(max_probabilities):.4f}\n")
                f.write(f"æœ€å¤§ç½®ä¿¡åº¦: {np.max(max_probabilities):.4f}\n")
                
                f.write("\nç½®ä¿¡åº¦åŒºé—´åˆ†å¸ƒ:\n")
                f.write("-" * 30 + "\n")
                confidence_ranges = {
                    'é«˜ç½®ä¿¡åº¦ (>0.8)': np.sum(max_probabilities > 0.8),
                    'ä¸­ç­‰ç½®ä¿¡åº¦ (0.6-0.8)': np.sum((max_probabilities > 0.6) & (max_probabilities <= 0.8)),
                    'ä½Žç½®ä¿¡åº¦ (0.4-0.6)': np.sum((max_probabilities > 0.4) & (max_probabilities <= 0.6)),
                    'å¾ˆä½Žç½®ä¿¡åº¦ (<=0.4)': np.sum(max_probabilities <= 0.4)
                }
                
                total_samples = len(max_probabilities)
                for range_name, count in confidence_ranges.items():
                    percentage = count / total_samples * 100
                    f.write(f"{range_name}: {count} ä¸ªæ ·æœ¬ ({percentage:.1f}%)\n")
            
            print(f"æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
            
            # ä¿å­˜ç®€åŒ–çš„æ ‡ç­¾æ–‡ä»¶ï¼ˆä»…åŒ…å«æ ·æœ¬IDå’Œé¢„æµ‹æ ‡ç­¾ï¼‰
            simple_results = pd.DataFrame({
                'sample_id': self.sample_ids,
                'predicted_label': predicted_labels
            })
            
            simple_path = f'{self.results_dir}/target_domain_labels.csv'
            simple_results.to_csv(simple_path, index=False, encoding='utf-8-sig')
            print(f"ç®€åŒ–æ ‡ç­¾æ–‡ä»¶å·²ä¿å­˜åˆ°: {simple_path}")
            
            return results_df
            
        except Exception as e:
            print(f"ä¿å­˜ç»“æžœå¤±è´¥: {e}")
            return None
    
    def run_complete_prediction(self):
        """è¿è¡Œå®Œæ•´çš„é¢„æµ‹æµç¨‹"""
        print("å¼€å§‹ç›®æ ‡åŸŸè¿ç§»å­¦ä¹ é¢„æµ‹æµç¨‹")
        print("=" * 50)
        
        # 1. åŠ è½½æ¨¡åž‹
        if not self.load_model():
            print("æ¨¡åž‹åŠ è½½å¤±è´¥ï¼Œç»ˆæ­¢é¢„æµ‹æµç¨‹")
            return False
        
        # 2. åŠ è½½ç›®æ ‡åŸŸæ•°æ®
        if not self.load_target_data():
            print("ç›®æ ‡åŸŸæ•°æ®åŠ è½½å¤±è´¥ï¼Œç»ˆæ­¢é¢„æµ‹æµç¨‹")
            return False
        
        # 3. è¿›è¡Œé¢„æµ‹
        predicted_labels = self.predict_target_domain()
        if predicted_labels is None:
            print("é¢„æµ‹å¤±è´¥ï¼Œç»ˆæ­¢é¢„æµ‹æµç¨‹")
            return False
        
        # 4. åˆ†æžç½®ä¿¡åº¦
        self.analyze_prediction_confidence()
        
        # 5. åˆ›å»ºå¯è§†åŒ–
        self.create_visualizations(predicted_labels)
        
        # 6. ä¿å­˜ç»“æžœ
        results_df = self.save_prediction_results(predicted_labels)
        
        print("\n" + "=" * 50)
        print("ç›®æ ‡åŸŸè¿ç§»å­¦ä¹ é¢„æµ‹æµç¨‹å®Œæˆï¼")
        print(f"ç»“æžœæ–‡ä»¶ä¿å­˜åœ¨: {self.results_dir}/")
        
        return True


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ç›®æ ‡åŸŸè¿ç§»å­¦ä¹ é¢„æµ‹ç³»ç»Ÿ")
    print("=" * 60)
    
    # æ–‡ä»¶è·¯å¾„
    #éšæœºæ£®æž—è·¯å¾„
    # model_path = r"d:\ç ”ç©¶ç”Ÿ\åŽä¸ºæ¯\pythonProject1\result-2\best_bearing_model.pkl"

    #stackingè·¯å¾„
    model_path = r"D:\ç ”ç©¶ç”Ÿ\åŽä¸ºæ¯\pythonProject1\result-22\rank_5_Stacking_Optimized_model.pkl"

    target_data_path = r"d:\ç ”ç©¶ç”Ÿ\åŽä¸ºæ¯\pythonProject1\Q3è¿ç§»å­¦ä¹ \target_domain_features_standardized.csv"
    
    print(f"æ¨¡åž‹æ–‡ä»¶è·¯å¾„: {model_path}")
    print(f"æ•°æ®æ–‡ä»¶è·¯å¾„: {target_data_path}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    model_exists = os.path.exists(model_path)
    data_exists = os.path.exists(target_data_path)
    
    print(f"æ¨¡åž‹æ–‡ä»¶å­˜åœ¨: {model_exists}")
    print(f"æ•°æ®æ–‡ä»¶å­˜åœ¨: {data_exists}")
    
    if not model_exists:
        print(f"é”™è¯¯: æ¨¡åž‹æ–‡ä»¶ä¸å­˜åœ¨ - {model_path}")
        return
    
    if not data_exists:
        print(f"é”™è¯¯: ç›®æ ‡åŸŸæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ - {target_data_path}")
        return
    
    try:
        # åˆ›å»ºé¢„æµ‹å™¨å¹¶è¿è¡Œ
        print("\næ­£åœ¨åˆå§‹åŒ–é¢„æµ‹å™¨...")
        predictor = TargetDomainPredictor(model_path, target_data_path)
        
        print("å¼€å§‹è¿è¡Œå®Œæ•´é¢„æµ‹æµç¨‹...")
        success = predictor.run_complete_prediction()
        
        if success:
            print("\nðŸŽ‰ è¿ç§»å­¦ä¹ é¢„æµ‹æˆåŠŸå®Œæˆï¼")
            print("ðŸ“Š è¯·æŸ¥çœ‹ç”Ÿæˆçš„å¯è§†åŒ–å›¾è¡¨å’Œç»“æžœæ–‡ä»¶")
        else:
            print("\nâŒ è¿ç§»å­¦ä¹ é¢„æµ‹å¤±è´¥")
            
    except Exception as e:
        print(f"\nâŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()